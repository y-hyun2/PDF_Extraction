"""ESG ë³´ê³ ì„œ íŒŒì´í”„ë¼ì¸ ì „ì²´ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸.

ìˆœì°¨ ì‹¤í–‰ ë‹¨ê³„
1. PDF ì¸ì½”ë”© ë³´ì • ì—¬ë¶€ ì²´í¬ (ìë™)
2. Docling êµ¬ì¡°í™” ì¶”ì¶œ
3. í‘œ í…ìŠ¤íŠ¸ ì¶”ì¶œ(OCR/PyMuPDF)
4. ê·¸ë¦¼ GPT ì„¤ëª… (ì˜µì…˜)
5. í‘œ ìˆ«ì ê²€ì¦(diff)
6. MySQL ì ì¬ (ì˜µì…˜)
7. ë²¡í„° DB êµ¬ì¶• (ì˜µì…˜)
8. ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (ì˜µì…˜)

ì˜ˆì‹œ:
    python src/run_pipeline.py --pdf data/input/report.pdf --pages 1-10 --load-db --build-vector-db \
        --search-queries "hybrid::íƒ„ì†Œ ë°°ì¶œ" "semantic::ì¬ìƒì—ë„ˆì§€ ê³„íš"
"""

import argparse
import subprocess
import sys
from pathlib import Path

# ì‹¤í–‰í•  ê°œë³„ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ ì •ì˜
SRC_DIR = Path(__file__).parent.resolve()
SCRIPT_PDF_EXTRACTOR = SRC_DIR / "pdf_text_extractor.py"
SCRIPT_STRUCTURED = SRC_DIR / "structured_extract.py"
SCRIPT_TABLE_OCR = SRC_DIR / "table_ocr.py"
SCRIPT_FIGURE_OCR = SRC_DIR / "figure_ocr.py"
SCRIPT_TABLE_DIFF = SRC_DIR / "table_diff.py"
SCRIPT_LOAD_DB = SRC_DIR / "load_to_db.py"
SCRIPT_BUILD_VECTOR = SRC_DIR / "build_vector_db.py"
SCRIPT_SEARCH_VECTOR = SRC_DIR / "search_vector_db.py"


def run_command(cmd: list[str], description: str):
    """í•˜ìœ„ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ê³µí†µ í¬ë§·ìœ¼ë¡œ ì‹¤í–‰."""
    print(f"\n{'='*60}")
    print(f"ğŸš€ [Pipeline] Starting: {description}")
    print(f"   Command: {' '.join(str(c) for c in cmd)}")
    print(f"{'='*60}\n")
    
    try:
        # Stream output to stdout
        result = subprocess.run(cmd, check=True)
    except subprocess.CalledProcessError as e:
        print(f"\nâŒ [Pipeline] Failed at step: {description}")
        print(f"   Exit Code: {e.returncode}")
        print("   Aborting pipeline.")
        sys.exit(e.returncode)
    
    print(f"\nâœ… [Pipeline] Completed: {description}\n")


def main():
    parser = argparse.ArgumentParser(description="ESG ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ê¸°")
    parser.add_argument("--pdf", type=Path, required=True, help="ì…ë ¥ PDF ê²½ë¡œ")
    parser.add_argument("--pages", type=str, default=None, help="ì²˜ë¦¬í•  í˜ì´ì§€ ë²”ìœ„ (ì˜ˆ: 1-10, 25)")
    parser.add_argument("--doc-name", type=str, default=None, help="ê²°ê³¼ í´ë”/DBì— ì‚¬ìš©í•  ë¬¸ì„œ ì´ë¦„ (ê¸°ë³¸: PDF íŒŒì¼ëª…(stem))")
    
    # Feature Flags
    parser.add_argument("--skip-sanitize", action="store_true", help="Skip the PDF sanitization check step")
    parser.add_argument("--skip-gpt", action="store_true", help="Skip GPT-based figure description")
    parser.add_argument("--load-db", action="store_true", help="Load results into MySQL database after processing")
    parser.add_argument("--init-db", action="store_true", help="Initialize DB schema before loading (use with --load-db)")

    # ì¶”ê°€ ê¸°ëŠ¥: ë²¡í„° DB êµ¬ì¶• + ê²€ìƒ‰ ìë™í™”
    parser.add_argument("--build-vector-db", action="store_true", help="í…Œì´ë¸”/ê·¸ë¦¼ ì ì¬ í›„ ë²¡í„° DBë„ ì¦‰ì‹œ êµ¬ì¶•")
    parser.add_argument(
        "--search-queries",
        nargs="*",
        default=None,
        help="ë²¡í„° ê²€ìƒ‰ì„ í•¨ê»˜ ìˆ˜í–‰í•  ì§ˆì˜ ëª©ë¡. 'mode::query' í˜•íƒœë¡œ ê°œë³„ ëª¨ë“œ ì§€ì • ê°€ëŠ¥",
    )
    parser.add_argument(
        "--search-mode",
        choices=("semantic", "keyword", "hybrid"),
        default="semantic",
        help="search-queriesì— ëª¨ë“œê°€ ëª…ì‹œë˜ì§€ ì•Šì•˜ì„ ë•Œ ì‚¬ìš©í•  ê¸°ë³¸ ëª¨ë“œ",
    )
    parser.add_argument("--search-top-k", type=int, default=5, help="ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜")
    
    args = parser.parse_args()

    # 0. Validate Input
    if not args.pdf.exists():
        print(f"Error: Input PDF not found: {args.pdf}")
        sys.exit(1)
        
    pdf_path = args.pdf.resolve()
    
    # 1. PDF Sanitization (Step 0)
    # The pdf_text_extractor.py tool handles the check logic internally.
    # It returns 0 if fine, or creates a sanitized file if needed.
    # However, structured_extract.py has logic to auto-switch to sanitized file.
    # WE MUST RUN sanitization check unless skipped.
    if not args.skip_sanitize:
        cmd_sanitize = [sys.executable, str(SCRIPT_PDF_EXTRACTOR), "--pdf", str(pdf_path)]
        # We don't check=True here because the script might return non-zero on error,
        # but current logic returns 1 on failure. We want to stop if sanitization fails.
        # But wait, pdf_text_extractor returns 0 on [Pass] as well. So check=True is fine.
        run_command(cmd_sanitize, "Step 0: PDF Sanitization Check")
    
    # Note: structured_extract.py has auto-switch logic, so we just pass the ORIGINAL path.
    # It will pick up the sanitized file if it exists.

    # 2. Structured Extraction
    cmd_struct = [sys.executable, str(SCRIPT_STRUCTURED), "--pdf", str(pdf_path)]
    if args.pages:
        cmd_struct.extend(["--pages", args.pages])
    else:
        # If no pages specified, structured_extract defaults to 3 pages safety limit.
        # But for full pipeline, we likely want full doc unless user specified.
        # Wait, user might want full. structured_extract.py needs explicit --pages or run all?
        # Standard structured_extract w/o --pages uses --count 3 default.
        # If user runs pipeline w/o --pages, they probably imply "FULL".
        # Let's check total pages first? OR just don't pass anything and let it default to 3? 
        # User request: "just run that file". Usually implies full pipeline on whatever range I asked.
        # If I asked --pages 1-10, pass it. If not, maybe warn?
        # Let's keep default behavior (3 pages) to be safe, or we can add a flag --full-doc.
        # Let's trust args.pages. If None, it does default.
        pass
        
    # êµ¬ì¡°í™” ê²°ê³¼ í´ë”ëª…ì„ doc_nameìœ¼ë¡œ ê³ ì • (PDF ì´ë¦„ ê¸°ë°˜)
    doc_name = args.doc_name or pdf_path.stem
    cmd_struct.extend(["--report-name", doc_name])

    run_command(cmd_struct, "Step 1: Docling Structured Extraction")
    
    # 3. Table OCR
    # Now we know exactly where the pages are: data/pages_structured/{doc_name}
    target_page_dir = Path("data/pages_structured") / doc_name
    
    cmd_tocr = [sys.executable, str(SCRIPT_TABLE_OCR)]
    if args.pages:
        cmd_tocr.extend(["--pages", args.pages])
    
    # í‘œ ì¶”ì¶œì€ êµ¬ì¡°í™” í´ë”ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •
    cmd_tocr.extend(["--structured-dir", str(target_page_dir)])
    cmd_tocr.extend(["--pdf", str(pdf_path)]) 
    
    run_command(cmd_tocr, "Step 2: Table Text Extraction (OCR/PDF)")
    
    # 4. Figure OCR
    if not args.skip_gpt:
        cmd_fig = [sys.executable, str(SCRIPT_FIGURE_OCR), "--model", "gpt-4o-mini"]
        if args.pages:
            cmd_fig.extend(["--pages", args.pages])
        cmd_fig.extend(["--structured-dir", str(target_page_dir)]) # Ensure we point to correct folder
        run_command(cmd_fig, "Step 3: Figure Description (GPT)")
    
    # 5. Table Diff
    cmd_diff = [sys.executable, str(SCRIPT_TABLE_DIFF)]
    if args.pages:
        cmd_diff.extend(["--pages", args.pages])
    cmd_diff.extend(["--structured-dir", str(target_page_dir)])
    run_command(cmd_diff, "Step 4: Table Validation (Diff)")
    
    # 6. DB ì ì¬
    if args.load_db:
        cmd_load = [sys.executable, str(SCRIPT_LOAD_DB), "--doc-name", doc_name]
        if args.init_db:
            cmd_load.append("--init-db")
        # Ensure loading script knows where to look
        cmd_load.extend(["--input-dir", str(target_page_dir)])
        
        run_command(cmd_load, "Step 5: Database Loading")

    # 7. ë²¡í„° DB êµ¬ì¶• (ì˜µì…˜)
    build_vector_flag = args.build_vector_db or (args.search_queries is not None and len(args.search_queries) > 0)
    if build_vector_flag:
        print("\nğŸ’¡ ë²¡í„° DBëŠ” DB ì ì¬ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ë¯€ë¡œ load_db ì‹¤í–‰ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        cmd_vector = [sys.executable, str(SCRIPT_BUILD_VECTOR), "--reset"]
        run_command(cmd_vector, "Step 6: Vector DB Build")

    # 8. ë²¡í„° ê²€ìƒ‰ (ì˜µì…˜)
    if args.search_queries:
        for raw_query in args.search_queries:
            if "::" in raw_query:
                mode, query = raw_query.split("::", 1)
                mode = mode.strip() or args.search_mode
            else:
                mode = args.search_mode
                query = raw_query
            query = query.strip()
            if not query:
                continue
            cmd_search = [
                sys.executable,
                str(SCRIPT_SEARCH_VECTOR),
                query,
                "--top-k",
                str(args.search_top_k),
                "--mode",
                mode,
            ]
            desc = f"Step 7: Vector Search ({mode} :: {query})"
            run_command(cmd_search, desc)

    print("\nâœ¨ [Pipeline] ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ")
    print(f"   - ê²°ê³¼ í´ë”: {target_page_dir}")
    if args.load_db:
        print(f"   - DB ì ì¬ ë¬¸ì„œëª…: {doc_name}")


if __name__ == "__main__":
    main()
