"""MySQL ë°ì´í„°ë¥¼ ì´ìš©í•´ í˜ì´ì§€/ì²­í¬ 2ë‹¨ê³„ ë²¡í„° DBë¥¼ êµ¬ì¶•í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸."""

from __future__ import annotations

import argparse
import base64
import json
import os
from collections import defaultdict
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Iterable, List

import chromadb
from langchain_text_splitters import RecursiveCharacterTextSplitter
from sentence_transformers import SentenceTransformer

# GPT ìš”ì•½ì„ ìœ„í•´ OpenAI í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
from openai import OpenAI

from load_to_db import get_connection

# ===== ì„¤ì • =====
REPO_ROOT = Path(__file__).resolve().parents[1]
STRUCTURED_ROOT = REPO_ROOT / "data" / "pages_structured"
BASE_DIR = Path("vector_db")
PAGE_COLLECTION = "esg_pages"
CHUNK_COLLECTION = "esg_chunks"
EMBEDDING_MODEL = "BAAI/bge-m3"
CHUNK_SIZE = 512
CHUNK_OVERLAP = 50
BATCH_SIZE = 32
PAGE_SUMMARY_PROMPT = """
You are an assistant tasked with summarizing images for retrieval.
These summaries will be embedded and used to retrieve the raw image.
Give a concise summary of the image that is well optimized for retrieval.

Instructions

- Image is page of sustainability report, and this RAG system will be used to QA task for ESG analyst.

- Summary should be in Korean.

- RAG ëª©ì ì— ë§ê²Œ ì œëª©, í‚¤ì›Œë“œ, ì£¼ìš” ë°ì´í„° ë¥¼ ì¶”ì¶œí•´ì£¼ê³ , ë‚´ìš©ì„ ë¹ ì§ì—†ì´ ëª¨ë‘ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ê³ , íŠ¹íˆ ì‚½ì…ëœ ì´ë¯¸ì§€ì™€ í‘œë¥¼ ì˜ ì¸ì‹í•´ì„œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì¤˜

- í˜ì´ì§€ê°€ ì„¹ì…˜ì„ êµ¬ë¶„í•˜ëŠ” í˜ì´ì§€ ì´ê±°ë‚˜, ì œëª©, ëª©ì°¨ì™€ ê°™ì€ í˜ì´ì§€ë¼ë©´, ë‚´ìš©ì„ ì§§ê²Œ ì‘ì„±í•˜ë„ë¡í•´.

- í˜ì´ì§€ì— ì •ë³´ê°€ ì ë‹¤ë©´, ë‚´ìš©ì´ ì ì–´ë„ ê´œì°®ê³ , ì •ë³´ê°€ ë§ë‹¤ë©´, ë‚´ìš©ì´ ëˆ„ë½ë˜ì§€ ì•Šê²Œ ìì„¸í•˜ê²Œ ì‘ì„±í•´.

- ìš”ì•½ ê²°ê³¼ í¬ë§·ì€ ë‹¤ìŒê³¼ ê°™ì•„.


ì˜ˆì‹œ í¬ë§·

---


ì œëª©: ê¸°í›„ë³€í™” ë¦¬ìŠ¤í¬ ë° ê¸°íšŒ ì˜ì‚¬ê²°ì • í”„ë¡œì„¸ìŠ¤ì™€ ì „ì‚¬ ëŒ€ì‘, ì˜¨ì‹¤ê°€ìŠ¤ ê°ì¶• ëª©í‘œ

í‚¤ì›Œë“œ: ê¸°í›„ë³€í™” ë¦¬ìŠ¤í¬, ê¸°í›„ë³€í™” ê¸°íšŒ, ì¤‘ëŒ€ì„± í‰ê°€, ESGìœ„ì›íšŒ, CEO, CLO(ESG ì´ê´„), ESGì¶”ì§„ ì‹¤ë¬´ë‹¨, ì „ì‚¬ ë¦¬ìŠ¤í¬ ê´€ë¦¬, ì˜¨ì‹¤ê°€ìŠ¤ (Scope1, Scope2, Scope3), ì¬ìƒì—ë„ˆì§€ ì‚¬ìš© ë¹„ìœ¨, ëŒ€ì‘ ë¡œë“œë§µ

ì£¼ìš” ë°ì´í„°:

- ì˜ì‚¬ê²°ì • í”„ë¡œì„¸ìŠ¤ í‘œ

- ì´ì‚¬íšŒ(ESGìœ„ì›íšŒ) â†’ ê²½ì˜ì§„(CEO, CLO) â†’ ì‹¤ë¬´ë‹¨(ESGì¶”ì§„)

- ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ (Scope1Â·2Â·3)

-â€ƒì¬ìƒì—ë„ˆì§€ ì‚¬ìš© ë¹„ìœ¨

- ì—°ê°„ ëª©í‘œ(ì¤‘ëŒ€ì„± í‰ê°€ ê²°ê³¼ ë°˜ì˜)

ìƒì„¸ ë‚´ìš©:

1. ê¸°í›„ë³€í™” ë¦¬ìŠ¤í¬ ë° ê¸°íšŒ ì˜ì‚¬ê²°ì • í”„ë¡œì„¸ìŠ¤

- ì¤‘ëŒ€ì„± í‰ê°€ ë° ë¦¬ìŠ¤í¬ ì¸ì‹

- ì¡°ì§ ë‚´ ê²€í† ë˜ëŠ” ê¸°í›„ë³€í™” ë¦¬ìŠ¤í¬ë¥¼ ë‹¤ë¥¸ ë¦¬ìŠ¤í¬ì™€ í•¨ê»˜ í‰ê°€, ìš°ì„ ìˆœìœ„ ê²°ì •

- í‰ê°€ ê³¼ì •: ë‚´ë¶€ ì˜í–¥ ë¶„ì„ â†’ ì´ìŠˆ ì‹ë³„Â·ë¶„ë¥˜ â†’ ì¤‘ëŒ€ì„± í‰ê°€ â†’ í•µì‹¬ ì´ìŠˆ ë„ì¶œ

- ì¤‘ëŒ€í•œ ë¦¬ìŠ¤í¬Â·ê¸°íšŒ ìš”ì¸ ë°œìƒ ì‹œ CLOì—ê²Œ ì¦‰ì‹œ ë³´ê³  í›„ í•„ìš”ì‹œ CEO, ESGìœ„ì›íšŒê¹Œì§€ ë‹¨ê³„ë³„ ë³´ê³ 

- ì˜ì‚¬ê²°ì • êµ¬ì¡°

- ì´ì‚¬íšŒ(ESGìœ„ì›íšŒ)

- í•µì‹¬ ê¸°í›„ë³€í™” ë¦¬ìŠ¤í¬Â·ê¸°íšŒì— ëŒ€í•œ ìµœì¢… ì˜ê²°

- SKí…”ë ˆì½¤ì— ì‹¬ê°í•œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì‚¬ì•ˆì— ëŒ€í•œ ì‹¬ì˜

- ê²½ì˜ì§„(CEO)

- ì¤‘ëŒ€í•œ ë¦¬ìŠ¤í¬Â·ê¸°íšŒ ìš”ì¸ì— ëŒ€í•œ ì˜ì‚¬ê²°ì •

- ì‚¬ì—…Â·ì¬ë¬´ì— ì‹¬ê°í•œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” í•µì‹¬ ì´ìŠˆ ë°œìƒ ì‹œ ESGìœ„ì›íšŒ ë³´ê³ 

- ê²½ì˜ì§„(CLO, ESG ì´ê´„)

- ê¸°í›„ë³€í™” ë¦¬ìŠ¤í¬Â·ê¸°íšŒê°€ ì¤‘ëŒ€í•œ ì‚¬ì•ˆì¼ ê²½ìš° CEO ë³´ê³ 

- ì˜í–¥ ë²”ìœ„ ë° ëŒ€ì‘ ë°©ì•ˆ ê²€í† , í•„ìš”ì‹œ ì´ì‚¬íšŒ(ESGìœ„ì›íšŒ)ì™€ ì‹¬ì˜

- ì‹¤ë¬´ë‹¨(ESGì¶”ì§„)

- ë¦¬ìŠ¤í¬Â·ê¸°íšŒ ìš”ì†Œ ëª¨ë‹ˆí„°ë§ ë° ì¤‘ëŒ€ì„± í‰ê°€(ë‚´ë¶€ ì˜í–¥ ë¶„ì„) ìˆ˜í–‰

- í‰ê°€ ê²°ê³¼ë¥¼ í† ëŒ€ë¡œ ëŒ€ì‘ ì‹œë‚˜ë¦¬ì˜¤ ìˆ˜ë¦½, ESGìœ„ì›íšŒÂ·ê²½ì˜ì§„ ë³´ê³ 

2. ê¸°í›„ë³€í™” ë¦¬ìŠ¤í¬ ë° ê¸°íšŒ ì „ì‚¬ ëŒ€ì‘ í”„ë¡œì„¸ìŠ¤

- ì˜ì‚¬ê²°ì • ì´í›„ í›„ì† ì¡°ì¹˜

- ESG ì¶”ì§„ ìœ ê´€ ë¶€ì„œê°€ ëŒ€ì‘ ë°©í–¥ ì„¤ì • â†’ ì¤‘ì¥ê¸° ê´€ì ì˜ ëŒ€ì•ˆ ë§ˆë ¨

- ë§¤ë…„ ìì²´ ê³„íš ë°˜ì˜ ë° ì´í–‰ ì„±ê³¼ ëª¨ë‹ˆí„°ë§, í•„ìš” ì‹œ ê³µê³µê¸°ê´€ ë“± ì´í•´ê´€ê³„ìì™€ í˜‘ë ¥

- ì „ì‚¬ ë¦¬ìŠ¤í¬ ëŒ€ì‘ ì²´ê³„ì— ê¸°í›„ë³€í™” ë¦¬ìŠ¤í¬Â·ê¸°íšŒë¥¼ í¬í•¨í•˜ì—¬ ìƒì‹œ ê´€ë¦¬

- ì£¼ìš” ì¶”ì§„ ë‚´ìš©

- ì •ê¸°Â·ìˆ˜ì‹œ ëª¨ë‹ˆí„°ë§: ê²½ì˜Â·ì¬ë¬´ì  ì˜í–¥, ì¡°ì§ ìš´ì˜ ë¦¬ìŠ¤í¬ ê²€í† 

- ì¤‘ëŒ€í•œ ì´ìŠˆ ë°œìƒ ì‹œ ESGìœ„ì›íšŒ ë³´ê³ ì™€ í•¨ê»˜ ë‚´ë¶€ í”„ë¡œì„¸ìŠ¤ ê°•í™”

- ì¤‘ëŒ€ì„± í‰ê°€ ê²°ê³¼ ë°˜ì˜ í›„ ì „ì‚¬ ì „ëµ ë° ëª©í‘œ ì¬ì¡°ì •

3. ê¸°í›„ë³€í™” ë¦¬ìŠ¤í¬ ë° ê¸°íšŒ ê´€ë ¨ ì§€í‘œì™€ ëª©í‘œ

- ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ (Scope1)

- ë‹¨ìœ„: tCOâ‚‚e

- 2020: 1,039,979

- 2021: 1,101,340

- 2022: 1,132,090

- ê°„ì ‘ ë°°ì¶œëŸ‰ (Scope2)

- ë‹¨ìœ„: tCOâ‚‚e

- 2020: 1,031,338

- 2021: 1,094,967

- 2022: 1,126,600

- ê¸°íƒ€ ê°„ì ‘ ë°°ì¶œëŸ‰ (Scope3)

- ë‹¨ìœ„: tCOâ‚‚e

- 2020: 6,918,286

- 2021: 6,925,159

- 2022: 7,059,192

- ì¬ìƒì—ë„ˆì§€ ì‚¬ìš© ë¹„ìœ¨

- 2020: 1.0%

- 2021: 2.0%

- 2022: 2.5%

- ëª©í‘œ: 5.0%

- ì°¸ê³  ì‚¬í•­

- Scope1: ì§ì ‘ ë°°ì¶œ(ì—°ë£Œ ì‚¬ìš© ë“±)

- Scope2: ì „ê¸°Â·ì—´ ì‚¬ìš© ë“± ê°„ì ‘ ë°°ì¶œ

- Scope3: ë°¸ë¥˜ì²´ì¸ ì „ë°˜(êµ¬ë§¤, ë¬¼ë¥˜ ë“±)ì—ì„œ ë°œìƒí•˜ëŠ” ê¸°íƒ€ ê°„ì ‘ ë°°ì¶œ

- ì¬ìƒì—ë„ˆì§€ ì‚¬ìš© ë¹„ìœ¨: ì—°ê°„ ì „ë ¥ ì‚¬ìš©ëŸ‰ ëŒ€ë¹„ ì¬ìƒì—ë„ˆì§€ ë¹„ì¤‘

4. ìš”ì•½

- ì´ ë¬¸ì„œëŠ” SKí…”ë ˆì½¤ì´ ê¸°í›„ë³€í™” ë¦¬ìŠ¤í¬ ë° ê¸°íšŒë¥¼ ì¤‘ëŒ€ ë¦¬ìŠ¤í¬ë¡œ ì¸ì‹í•˜ê³ , ì´ì‚¬íšŒ(ESGìœ„ì›íšŒ)Â·ê²½ì˜ì§„Â·ì‹¤ë¬´ë‹¨ ê°„ í˜‘ì—…ì„ í†µí•´ ì‹ë³„Â·ìš°ì„ ìˆœìœ„í™”Â·ëŒ€ì‘ ë°©ì•ˆì„ ê²°ì •í•˜ëŠ” ê³¼ì •ì„ ìƒì„¸íˆ ë‹¤ë£¸

- ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œ(Scope1Â·2Â·3) ì¶”ì´ì™€ ì¬ìƒì—ë„ˆì§€ ì‚¬ìš© ëª©í‘œ ë“± ì£¼ìš” ì§€í‘œë¥¼ ê³µê°œí•˜ê³ , ë§¤ë…„ ì¤‘ëŒ€ì„± í‰ê°€ì™€ ESG ì „ëµ ìˆ˜ì •Â·ì´í–‰ ëª¨ë‹ˆí„°ë§ì„ ë°˜ë³µí•˜ì—¬ ë¦¬ìŠ¤í¬ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ë‚´ìš©ì„ ì œì‹œí•¨
"""



def get_or_create_collections(client: chromadb.PersistentClient, reset: bool):
    if reset:
        for name in (PAGE_COLLECTION, CHUNK_COLLECTION):
            try:
                client.delete_collection(name)
            except Exception:
                pass
    page_col = client.get_or_create_collection(PAGE_COLLECTION, metadata={"hnsw:space": "cosine"})
    chunk_col = client.get_or_create_collection(CHUNK_COLLECTION, metadata={"hnsw:space": "cosine"})
    return page_col, chunk_col


def fetch_pages(conn) -> List[Dict[str, Any]]:
    sql = """
        SELECT d.id AS doc_id,
               d.filename,
               d.company_name,
               d.report_year,
               p.id AS page_id,
               p.page_no,
               p.full_markdown,
               p.image_path
        FROM pages p
        JOIN documents d ON p.doc_id = d.id
        WHERE p.full_markdown IS NOT NULL AND p.full_markdown != ''
        ORDER BY d.id, p.page_no
    """
    with conn.cursor() as cursor:
        cursor.execute(sql)
        return cursor.fetchall()


def fetch_figures(conn) -> List[Dict[str, Any]]:
    sql = """
        SELECT f.id AS figure_id,
               f.doc_id,
               f.page_id,
               p.page_no,
               f.caption,
               f.description,
               f.image_path,
               d.company_name,
               d.report_year,
               d.filename
        FROM doc_figures f
        JOIN pages p ON f.page_id = p.id
        JOIN documents d ON f.doc_id = d.id
        WHERE f.description IS NOT NULL AND CHAR_LENGTH(f.description) > 0
    """
    with conn.cursor() as cursor:
        cursor.execute(sql)
        return cursor.fetchall()


def fetch_tables(conn) -> List[Dict[str, Any]]:
    sql = """
        SELECT t.id AS table_id,
               t.doc_id,
               t.page_id,
               t.page_no,
               t.title,
               t.image_path,
               t.diff_data,
               d.company_name,
               d.report_year,
               d.filename
        FROM doc_tables t
        JOIN documents d ON t.doc_id = d.id
        ORDER BY t.doc_id, t.page_no, t.id
    """
    with conn.cursor() as cursor:
        cursor.execute(sql)
        return cursor.fetchall()


def fetch_table_cells(conn, table_ids: Iterable[int]) -> Dict[int, List[Dict[str, Any]]]:
    table_ids = list(table_ids)
    if not table_ids:
        return {}
    placeholders = ",".join(["%s"] * len(table_ids))
    sql = f"""
        SELECT table_id, row_idx, col_idx, content, is_header
        FROM table_cells
        WHERE table_id IN ({placeholders})
        ORDER BY table_id, row_idx, col_idx
    """
    with conn.cursor() as cursor:
        cursor.execute(sql, table_ids)
        rows = cursor.fetchall()
    grouped: Dict[int, List[Dict[str, Any]]] = defaultdict(list)
    for row in rows:
        grouped[row["table_id"]].append(row)
    return grouped


def build_table_text(table_meta: Dict[str, Any], cells: List[Dict[str, Any]]) -> str:
    rows: Dict[int, List[str]] = defaultdict(list)
    for cell in cells:
        text = (cell.get("content") or "").strip()
        rows[cell["row_idx"]].append((cell["col_idx"], text))

    ordered_lines: List[str] = []
    for row_idx in sorted(rows.keys()):
        cols = [text for _, text in sorted(rows[row_idx], key=lambda pair: pair[0])]
        ordered_lines.append(" | ".join(cols).strip())

    title = table_meta.get("title") or "(ì œëª© ì—†ìŒ)"
    lines = [f"í‘œ ì œëª©: {title}", "í‘œ ë‚´ìš©:"] + ordered_lines
    if table_meta.get("diff_data"):
        diff_str = table_meta["diff_data"]
        if isinstance(diff_str, dict):
            diff_repr = json.dumps(diff_str, ensure_ascii=False)
        else:
            diff_repr = str(diff_str)
        lines.append(f"ê²€ì¦ ì •ë³´: {diff_repr}")
    return "\n".join(lines).strip()


def build_page_context(page_row: Dict[str, Any], figure_texts: List[str], table_titles: List[str]) -> str:
    base = [
        f"í˜ì´ì§€ {page_row['page_no']} ë³¸ë¬¸:",
        (page_row.get("full_markdown") or "").strip(),
    ]
    if table_titles:
        base.append("[ì´ í˜ì´ì§€ì˜ í‘œ]")
        base.extend(f"- {title}" for title in table_titles)
    if figure_texts:
        base.append("[ì´ í˜ì´ì§€ì˜ ê·¸ë¦¼ ìš”ì•½]")
        base.extend(figure_texts)
    return "\n".join(line for line in base if line).strip()


def summarize_page_with_gpt(client: OpenAI, page_no: int, context: str, image_path: Path | None) -> str:
    if client is None:
        raise RuntimeError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    user_content = (
        f"{PAGE_SUMMARY_PROMPT}\n\n"
        f"[í˜ì´ì§€ ë²ˆí˜¸]\n{page_no}\n\n"
        f"[í˜ì´ì§€ ë³¸ë¬¸ ë° ë¶€ê°€ ì •ë³´]\n{context}"
    )
    content_payload: list[dict] = [{"type": "input_text", "text": user_content}]
    if image_path and image_path.exists():
        image_b64 = encode_image_base64(image_path)
        content_payload.append(
            {
                "type": "input_image",
                "image_url": f"data:image/png;base64,{image_b64}",
            }
        )
    resp = client.responses.create(
        model="gpt-4o-mini",
        input=[{"role": "user", "content": content_payload}],
        temperature=0.3,
        max_output_tokens=800,
    )
    for item in resp.output or []:
        for content in getattr(item, "content", []) or []:
            text = getattr(content, "text", None)
            if text:
                return text
    raise RuntimeError(f"GPT ì‘ë‹µì´ ë¹„ì—ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ {page_no}")


def collect_page_metadata(page_row: Dict[str, Any], table_ids: List[int], figure_ids: List[int]) -> Dict[str, Any]:
    return {
        "doc_id": page_row["doc_id"],
        "page_id": page_row["page_id"],
        "page_no": page_row["page_no"],
        "company_name": page_row.get("company_name") or "Unknown",
        "report_year": page_row.get("report_year") or 0,
        "filename": page_row["filename"],
        "page_image_path": page_row.get("image_path") or "",
        "table_ids": json.dumps([str(tid) for tid in table_ids]),
        "figure_ids": json.dumps([str(fid) for fid in figure_ids]),
        "created_at": datetime.now().isoformat(),
    }


def chunk_text(text: str, splitter: RecursiveCharacterTextSplitter) -> List[str]:
    text = (text or "").strip()
    if not text:
        return []
    return splitter.split_text(text)


def encode_image_base64(image_path: Path) -> str:
    data = image_path.read_bytes()
    return base64.b64encode(data).decode("utf-8")


def embed_and_upsert(collection, model, ids, documents, metadatas):
    if not ids:
        return
    for start in range(0, len(ids), BATCH_SIZE):
        batch_ids = ids[start:start + BATCH_SIZE]
        batch_docs = documents[start:start + BATCH_SIZE]
        batch_metas = metadatas[start:start + BATCH_SIZE]
        embeddings = model.encode(batch_docs).tolist()
        collection.upsert(ids=batch_ids, documents=batch_docs, embeddings=embeddings, metadatas=batch_metas)


def build_vector_db(reset: bool = False) -> None:
    print(f"ğŸš€ 2ë‹¨ê³„ ë²¡í„° DB êµ¬ì¶• ì‹œì‘ (ëª¨ë¸: {EMBEDDING_MODEL})")
    client = chromadb.PersistentClient(path=str(BASE_DIR.resolve()))
    page_collection, chunk_collection = get_or_create_collections(client, reset)

    print("ğŸ“¦ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
    model = SentenceTransformer(EMBEDDING_MODEL)
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP,
        separators=["\n\n", "\n", ". ", " "]
    )

    api_key = os.getenv("OPENAI_API_KEY") or os.getenv("OPEN_AI_API_KEY")
    if not api_key:
        raise RuntimeError("OPENAI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤ (í˜ì´ì§€ GPT ìš”ì•½ ë‹¨ê³„).")
    gpt_client = OpenAI(api_key=api_key)

    conn = get_connection()
    try:
        pages = fetch_pages(conn)
        figures = fetch_figures(conn)
        tables = fetch_tables(conn)
    finally:
        conn.close()

    if not pages:
        print("MySQLì—ì„œ í˜ì´ì§€ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. load_to_db.py ì‹¤í–‰ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    print(f"ğŸ“„ í˜ì´ì§€ {len(pages)}ê±´ / ê·¸ë¦¼ {len(figures)}ê±´ / í‘œ {len(tables)}ê±´ ë¡œë“œ ì™„ë£Œ")

    figures_by_page: Dict[int, List[Dict[str, Any]]] = defaultdict(list)
    for fig in figures:
        figures_by_page[fig["page_id"]].append(fig)

    tables_by_page: Dict[int, List[Dict[str, Any]]] = defaultdict(list)
    for tbl in tables:
        tables_by_page[tbl["page_id"]].append(tbl)

    # í˜ì´ì§€ ëŒ€í‘œ í…ìŠ¤íŠ¸ ìƒì„±
    page_ids: List[str] = []
    page_docs: List[str] = []
    page_metas: List[Dict[str, Any]] = []

    for page in pages:
        fig_texts: List[str] = []
        fig_ids: List[int] = []
        for fig in figures_by_page.get(page["page_id"], []):
            desc = (fig.get("description") or "").strip()
            if desc:
                fig_texts.append(f"- {desc}")
            fig_ids.append(fig["figure_id"])

        table_titles = []
        tbl_ids = []
        for tbl in tables_by_page.get(page["page_id"], []):
            title = tbl.get("title") or f"í‘œ {tbl['table_id']}"
            table_titles.append(title)
            tbl_ids.append(tbl["table_id"])

        doc_folder = Path(page["filename"]).stem
        image_rel = page.get("image_path")
        image_abs = STRUCTURED_ROOT / doc_folder / image_rel if image_rel else None

        context_text = build_page_context(page, fig_texts, table_titles)
        summary_text = summarize_page_with_gpt(gpt_client, page["page_no"], context_text, image_abs)
        page_ids.append(f"page_repr_{page['page_id']}")
        page_docs.append(summary_text)
        page_metas.append(collect_page_metadata(page, tbl_ids, fig_ids))

    print(f"ğŸ§¾ í˜ì´ì§€ ëŒ€í‘œ í…ìŠ¤íŠ¸ {len(page_ids)}ê±´ ì„ë² ë”©")
    embed_and_upsert(page_collection, model, page_ids, page_docs, page_metas)

    # ì •ë°€ ì²­í¬ ì²˜ë¦¬
    chunk_ids: List[str] = []
    chunk_docs: List[str] = []
    chunk_metas: List[Dict[str, Any]] = []

    for page in pages:
        # í˜ì´ì§€ ë³¸ë¬¸ ì²­í¬
        chunks = chunk_text(page["full_markdown"], splitter)
        for idx, chunk in enumerate(chunks):
            chunk_ids.append(f"page_{page['page_id']}_chunk_{idx}")
            chunk_docs.append(chunk)
            chunk_metas.append({
                "source_type": "page_text",
                "doc_id": page["doc_id"],
                "page_id": page["page_id"],
                "page_no": page["page_no"],
                "chunk_index": idx,
                "company_name": page.get("company_name") or "Unknown",
                "report_year": page.get("report_year") or 0,
                "filename": page["filename"],
                "created_at": datetime.now().isoformat(),
            })

        # í˜ì´ì§€ ë‚´ í…Œì´ë¸” í…ìŠ¤íŠ¸
        page_tables = tables_by_page.get(page["page_id"], [])
        table_cells_map = fetch_table_cells(get_connection(), [tbl["table_id"] for tbl in page_tables])
        for tbl in page_tables:
            cells = table_cells_map.get(tbl["table_id"], [])
            table_text = build_table_text(tbl, cells)
            chunk_ids.append(f"table_{tbl['table_id']}")
            chunk_docs.append(table_text)
            chunk_metas.append({
                "source_type": "table",
                "doc_id": tbl["doc_id"],
                "page_id": tbl["page_id"],
                "page_no": tbl["page_no"],
                "table_id": tbl["table_id"],
                "table_title": tbl.get("title") or "",
                "company_name": tbl.get("company_name") or "Unknown",
                "report_year": tbl.get("report_year") or 0,
                "filename": tbl["filename"],
                "image_path": tbl.get("image_path") or "",
                "diff_present": bool(tbl.get("diff_data")),
                "created_at": datetime.now().isoformat(),
            })

        # í˜ì´ì§€ ë‚´ ê·¸ë¦¼ ì„¤ëª…
        for fig in figures_by_page.get(page["page_id"], []):
            desc = (fig.get("description") or "").strip()
            if not desc:
                continue
            figure_text = f"ìº¡ì…˜: {fig.get('caption') or ''}\n\n{desc}"
            chunk_ids.append(f"figure_{fig['figure_id']}")
            chunk_docs.append(figure_text)
            chunk_metas.append({
                "source_type": "figure",
                "doc_id": fig["doc_id"],
                "page_id": fig["page_id"],
                "page_no": fig["page_no"],
                "figure_id": fig["figure_id"],
                "company_name": fig.get("company_name") or "Unknown",
                "report_year": fig.get("report_year") or 0,
                "filename": fig["filename"],
                "image_path": fig.get("image_path") or "",
                "created_at": datetime.now().isoformat(),
            })

    print(f"ğŸ” ì •ë°€ ì²­í¬ {len(chunk_ids)}ê±´ ì„ë² ë”©")
    embed_and_upsert(chunk_collection, model, chunk_ids, chunk_docs, chunk_metas)

    print(f"âœ… í˜ì´ì§€ ì»¬ë ‰ì…˜ ë²¡í„° ìˆ˜: {page_collection.count()}")
    print(f"âœ… ì²­í¬ ì»¬ë ‰ì…˜ ë²¡í„° ìˆ˜: {chunk_collection.count()}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--reset", action="store_true", help="ê¸°ì¡´ ë²¡í„° DBë¥¼ ì´ˆê¸°í™”í•˜ê³  ì¬êµ¬ì¶•")
    args = parser.parse_args()

    build_vector_db(reset=args.reset)
def summarize_page_with_gpt(client: OpenAI, page_no: int, context: str, image_path: Path | None) -> str:
    """GPT-4oì—ê²Œ í˜ì´ì§€ ìš”ì•½ì„ ìš”ì²­í•œë‹¤. ì´ë¯¸ì§€ë„ í•¨ê»˜ ì²¨ë¶€."""
    if client is None:
        raise RuntimeError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    user_content = (
        f"{PAGE_SUMMARY_PROMPT}\n\n"
        f"[í˜ì´ì§€ ë²ˆí˜¸]\n{page_no}\n\n"
        f"[í˜ì´ì§€ ë³¸ë¬¸ ë° ë¶€ê°€ ì •ë³´]\n{context}"
    )
    content_payload: list[dict] = [{"type": "text", "text": user_content}]
    if image_path and image_path.exists():
        image_b64 = encode_image_base64(image_path)
        content_payload.append(
            {
                "type": "input_image",
                "image_url": {"url": f"data:image/png;base64,{image_b64}"},
            }
        )
    resp = client.responses.create(
        model="gpt-4o-mini",
        input=[{"role": "user", "content": content_payload}],
        temperature=0.3,
        max_output_tokens=800,
    )
    for item in resp.output or []:
        for content in getattr(item, "content", []) or []:
            text = getattr(content, "text", None)
            if text:
                return text
    raise RuntimeError(f"GPT ì‘ë‹µì´ ë¹„ì—ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ {page_no}")
